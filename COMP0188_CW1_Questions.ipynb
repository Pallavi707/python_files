{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pallavi707/python_files/blob/master/COMP0188_CW1_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8J_m5g3yEH"
      },
      "source": [
        "# Coursework 1: Chest X-ray (100 marks)\n",
        "\n",
        "In this coursework, you will be working with the Kaggle [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data) dataset. You will analyze the dataset, and train deep learning models to classify whether an x-ray exhibits pneumonia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3nJRr1B3yEK"
      },
      "source": [
        "The coursework is structured as follows:\n",
        "\n",
        "1. Data Analysis: 5 marks\n",
        "2. Data Preparation: 5 marks\n",
        "3. Training a Baseline: 30 marks\n",
        "4. Improving the Baseline: 50 marks\n",
        "5. Evaluating on the Test Set: 10 marks\n",
        "\n",
        "In each question will require you tocode up a solution, and to briefly explain and discuss your choices and results.\n",
        "\n",
        "__IMPORTANT__\n",
        "* Pretrained models are __NOT__ allowed. You will recieve __0__ marks for any use of pretrained models.\n",
        "* The use of LLM/AI support including writing and coding aligns to the UCL guidelines. This includes the use of code prompts and Gemini in Google Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdf12jco3yEL"
      },
      "source": [
        "Here are some additional tips:\n",
        "- We recommend using weights and biases to log your training runs. This will allow you to easily compare previous runs if needed.\n",
        "- Ensure your results are reproducable - we may rerun your notebook to check for this. Points will be lost if results are not reproducable.\n",
        "- We recommend factorizing your code in places where you will be repeatedly using the same functionaility. For example, if you are training multiple models, consider using a common training loop function.\n",
        "- Your code and results and discussions should be concise, well-presented, and easy to read. Each question has a certain portion of marks going towards this.\n",
        "- Ensure you correctly use the train, validation, and test set throughout. You should only ever use the test set once - for the final evaluation.\n",
        "- Consider saving your models so you can reload previous models for the final evaluation\n",
        "- Ensure it is clear to the reader what any plots / figures are presenting. I.e., label axes, include titles, ensure it is clear what experiment it is from (what model / design choices, etc.)\n",
        "- Google Collab restricts the amount of GPU time available. Consider debugging code, using a subset of data, on CPU compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aBDQxq2e3yEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b78bb6-fcb1-4aa9-ac09-f461a39ea5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get the following error when running the import cell below this description:\n",
        "\n",
        "\n",
        "```\n",
        "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
        "```\n",
        "You will need to create a kaggle account, and navigate to https://www.kaggle.com/me/account. Navigate to \"API\" and create a new token. This will automatically download a json file called \"kaggle.json\".\n",
        "\n",
        "Run the following code, replacing the \"INSERT JSON HERE TEXT\" with the contents of the json that you downloaded.\n",
        "\n",
        "```\n",
        "!mkdir /root/.config/kaggle\n",
        "!touch /root/.config/kaggle/kaggle.json\n",
        "\n",
        "api_token = INSERT JSON HERE TEXT\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.config/kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "INSERT JSON HERE TEXT should be something of the form:\n",
        "```\n",
        "{\"username\":\"XXX\",\"key\":\"XXX\"}\n",
        "```"
      ],
      "metadata": {
        "id": "MNGPJcxblyhM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzTtYHbX3yEM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Y454o63yEN"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqB_JTQi3yEN"
      },
      "source": [
        "# Load and Re-split the Raw Data\n",
        "\n",
        "The original data is poorly split, so we will resplit it here. Do NOT edit this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e2WyfzM3yEN"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1  # This is implicitly defined as 1 - (TRAIN_SPLIT + VAL_SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEdJHUHQ3yEN"
      },
      "outputs": [],
      "source": [
        "# Set up the Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Specify the dataset\n",
        "dataset = \"paultimothymooney/chest-xray-pneumonia\"\n",
        "\n",
        "# Specify the download path\n",
        "download_path = \"chest_xray_dataset\"\n",
        "\n",
        "# Check if the dataset is already downloaded\n",
        "if os.path.exists(os.path.join(download_path, \"chest_xray\")):\n",
        "    print(f\"Dataset already exists at {download_path}. Skipping download.\")\n",
        "else:\n",
        "    # Create the download directory if it doesn't exist\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "    # Download the dataset\n",
        "    print(f\"Downloading {dataset} to {download_path}\")\n",
        "    api.dataset_download_files(dataset, path=download_path, unzip=True)\n",
        "    print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knFl_TAC3yEO"
      },
      "outputs": [],
      "source": [
        "# Re-split data\n",
        "dataset_path = os.path.join(download_path, \"chest_xray\")\n",
        "new_dataset_path = \"chest_xray_dataset_new_split\"\n",
        "\n",
        "if not os.path.exists(new_dataset_path):\n",
        "    # Create new directory structure\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in ['NORMAL', 'PNEUMONIA']:\n",
        "            os.makedirs(os.path.join(new_dataset_path, split, cls), exist_ok=True)\n",
        "\n",
        "    for cls in ['NORMAL', 'PNEUMONIA']:\n",
        "        all_files = []\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            source_folder = os.path.join(dataset_path, split, cls)\n",
        "            files = os.listdir(source_folder)\n",
        "            all_files.extend([(file, source_folder) for file in files])\n",
        "\n",
        "        # Sort files to ensure consistent order before shuffling\n",
        "        all_files.sort()\n",
        "\n",
        "        # Create a new Random object with the seed\n",
        "        rng = random.Random(42)\n",
        "\n",
        "        # Use the shuffle method of the Random object\n",
        "        rng.shuffle(all_files)\n",
        "\n",
        "        total_files = len(all_files)\n",
        "        train_end = int(total_files * TRAIN_SPLIT)\n",
        "        val_end = int(total_files * (TRAIN_SPLIT + VAL_SPLIT))\n",
        "\n",
        "        train_files = all_files[:train_end]\n",
        "        val_files = all_files[train_end:val_end]\n",
        "        test_files = all_files[val_end:]\n",
        "\n",
        "        for split, file_list in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
        "            for file, source_folder in file_list:\n",
        "                source = os.path.join(source_folder, file)\n",
        "                dest = os.path.join(new_dataset_path, split, cls, file)\n",
        "                shutil.copy(source, dest)\n",
        "\n",
        "    print(f\"Data re-split complete. New dataset location: {new_dataset_path}\")\n",
        "else:\n",
        "    print(f\"Re-split dataset already exists at {new_dataset_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCEwmeP03yEO"
      },
      "source": [
        "# Question 1: Data Analysis (5 marks)\n",
        "\n",
        "Perform some basic analysis of the statistics of the dataset.\n",
        "\n",
        "Try to spot anything that may impact how you will design your deep learning classifier and training.\n",
        "\n",
        "We'd expect to see:\n",
        "* Analysis of labels (target variable);\n",
        "* Analysis of input features;\n",
        "\n",
        "If you do spot anything, briefly explain **how you think it may impact training**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFr_0-h3yEP"
      },
      "outputs": [],
      "source": [
        "# Collect dataset statistics\n",
        "splits = ['train', 'val', 'test']\n",
        "classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "stats = {split: {cls: 0 for cls in ['NORMAL', 'PNEUMONIA']} for split in ['train', 'val', 'test']}\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        path = os.path.join(new_dataset_path, split, cls)\n",
        "        stats[split][cls] = len(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOewT8sA3yEP"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiuMf1ce3yEP"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_Insert brief discussion of analysis here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDN6YQeP3yEP"
      },
      "source": [
        "# Question 2: Data Preparation (5 marks)\n",
        "\n",
        "Here, you should load the dataset into torch dataloaders, performing any preprocessing required in the process.\n",
        "\n",
        "Within the ChestXrayDataset class, the root_dir parameter is a string defining the directory containing the \"train\", \"val\" and \"test\" folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcBeWbFP3yEP"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"chest_xray_dataset_new_split\"\n",
        "batch_size ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atk7VPI23yEQ"
      },
      "outputs": [],
      "source": [
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMEI4zhT3yEQ"
      },
      "outputs": [],
      "source": [
        "# Define data transforms\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fa080DI3yEQ"
      },
      "outputs": [],
      "source": [
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "# Create datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "# Print dataset sizes\n",
        "\n",
        "# Print batch shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZelQODT83yEQ"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_Insert brief discussion of any design choices you made here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty37YSYK3yEQ"
      },
      "source": [
        "# Question 3: Training a Baseline (30 marks)\n",
        "\n",
        "You will now establish an initial baseline model and training procedure. This should be as simple as possible, without using any elaborate design choices, whilst still obtaining reasonable performance (i.e., at least better than random chance). You will attempt to improve upon this baseline in later questions.\n",
        "\n",
        "When answering this question, consider what makes a good baseline:\n",
        "* Easily converges;\n",
        "* Easy to implement;\n",
        "* Established architectural components that have proved well suited to the data-type and problem.\n",
        "* Obtains reasonable performance e.g, better than random guess\n",
        "\n",
        "You will be required to explain your design choices, and to present and discuss you results.\n",
        "\n",
        "The code below is a suggested structure to guide you. You are free to deviate from this __however, it must be obvious to the marker__:\n",
        "* What the final proposed baseline model is (in terms of architecture);\n",
        "* What the performance of the baseline model is and how the model has been trained;\n",
        "* What your written justification and discussion is;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzUuFDRc3yEQ"
      },
      "outputs": [],
      "source": [
        "num_epochs =\n",
        "use_wandb = False  # Set to True if you want to use wandb\n",
        "lr ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j6klXIC3yEQ"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class SimpleModel(nn.Module):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0xh1jau3yER"
      },
      "outputs": [],
      "source": [
        "def calculate_class_accuracy(outputs, labels):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EPsfC5s3yER"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device='cuda', use_wandb=False):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "# Feel free to add more intermediate functions to do this\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONedb4HQ3yER"
      },
      "outputs": [],
      "source": [
        "def plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "# Add all your plotting code here. Feel free to use intermediate functions\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5bwRdrU3yER"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPUy57xr3yER"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_Insert brief explanation of the design choices you made_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy-HoUkkecEr"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc. here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--x4N1w3yES"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5YLFof3yES"
      },
      "source": [
        "# Question 4: Improving the Baseline (50 marks)\n",
        "After analysing the results of your baseline, can you spot any clear areas for improvement, or think of any obvious improvements to your model and training setup that will improve performance?\n",
        "\n",
        "You are free to try out as many improvements as you want here. You may also try modifying aspects of the data.\n",
        "\n",
        "**However, for the final code and results you present in your submission, you should use exactly 3 design choices which (attempt to) improve upon the baseline.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8C8cR5govik"
      },
      "source": [
        "Tips:\n",
        "* If you struggle to improve upon the baseline, but your design choices are well motivated and well implemented, and your results are well-presented and discussed, you will still receive most marks here. You will get some extra marks for improving upon baseline performance, but you will primarily be marked for making reasonable design choices.\n",
        "* A small number of marks will be deducted if there are extremely obvious issues with the baseline that you do not attempt to address"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJb8yLNffD22"
      },
      "source": [
        "## Q 4.1: Final improved model -- baseline + 3 improvements (20 marks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0ARZtLmgDGh"
      },
      "source": [
        "You should now choose three final improvements. Explain them, implement them, train a model, and present and discuss the results.\n",
        "\n",
        "Try to maximize performance with the final three improvements you choose (i.e., pick the three best improvements you found)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e1-IBUhg_Xj"
      },
      "outputs": [],
      "source": [
        "# Implement the improvements and train the model in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wegv4NKFg3W7"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "*Insert a brief explanation of the three improvements you have used*\n",
        "\n",
        "*For each improvment:*\n",
        "1. *State the change being made;*\n",
        "2. *State **why** this change could, in theory, improve the performance of the baseline model. If possible, motivate your hypothesis using empirical evidence from the baseline models results*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZc77acWhMEM"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_\n",
        "\n",
        "(Hint: ensure you compare to the baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7z2sLUxhWhd"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIj57HG2fWll"
      },
      "source": [
        "## Q 4.2: Empirically justify improvement 1 (10 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGgAxZ3hlwVa"
      },
      "source": [
        "Now you will empirically demonstrate the contribution of each improvement to the final performance of your model.\n",
        "\n",
        "To justify the utility of an improvement, you should present one of the following experiments:\n",
        "- *Option 1:* Train the final model _without_ that improvement (but still with the other two improvements). Compare these results to the results you presented previously with all three improvements. If the improvement is useful, removing it should result in a drop in performance\n",
        "- *Option 2:* Compare the performance of baseline to the perfroamnce of the baseline plus a single improvement. If the improvement is useful, you should expect improved performance versus the baseline.\n",
        "\n",
        "You will still get a significant portion of the marks if the proposed improvement was well-motivated but does not empirically improve perfromance. In this case, ensure your discussion touches on why performance may not have improved or any other interesting talking points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA2yiCs2nnMp"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk8Uzkgmn4gZ"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCYUpvoYnpbg"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEIUdWktnu4Q"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vydel9XfjUv"
      },
      "source": [
        "## Q 4.3: Empirically justify improvement 2 (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_tnhBmLoN2a"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKvOHbc0oEHU"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh-bK3ScoEHc"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp8RIsSsoEHc"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goZoEDK-fk0-"
      },
      "source": [
        "## Q 4.4: Empirically justify improvement 3 (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxyMLFtUoOz6"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzu22nM4oCVK"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ywu9x_joCVT"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILe3TKZgoCVT"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrteSKJP3yEW"
      },
      "source": [
        "# Question 5: Final Evaluation (10 marks)\n",
        "\n",
        "You should perform a final evaluation of the performance of your model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPAaD8zD3yEW"
      },
      "outputs": [],
      "source": [
        "# Implement evaluation here\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVzR_Weo3yEW"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVQfQU0puHLJ"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "TA_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}